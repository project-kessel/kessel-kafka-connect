# debezium v2.7
apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: kafka-connectors
objects:
- apiVersion: kafka.strimzi.io/v1beta2
  kind: KafkaConnector
  metadata:
    name: hbi-migration-connector
    annotations:
      strimzi.io/use-connector-resources: "true"
    labels:
      strimzi.io/cluster: ${KAFKA_CONNECT_INSTANCE}
  spec:
    state: ${CONNECTOR_STATE}
    class: io.debezium.connector.postgresql.PostgresConnector
    tasksMax: ${{MAX_TASKS}}
    config:
      slot.name: debezium_hosts
      signal.enabled.channels: "source,kafka"
      signal.kafka.topic: "host-inventory.signal"
      signal.kafka.bootstrap.servers: ${BOOTSTRAP_SERVERS}
      signal.data.collection: "hbi.signal"
      database.server.name: host-inventory-db
      database.dbname: ${secrets:${DB_SECRET_NAME}:db.name}
      database.hostname: ${secrets:${DB_SECRET_NAME}:db.host}
      database.port: ${secrets:${DB_SECRET_NAME}:db.port}
      database.user: ${secrets:${DB_SECRET_NAME}:db.user}
      database.password: ${secrets:${DB_SECRET_NAME}:db.password}
      topic.prefix: host-inventory
      table.include.list: hbi.hosts_p.*
      plugin.name: pgoutput
      heartbeat.interval.ms: ${DEBEZIUM_HEARTBEAT_INTERVAL_MS}
      heartbeat.action.query: ${DEBEZIUM_ACTION_QUERY}
      topic.heartbeat.prefix: ${TOPIC_HEARTBEAT_PREFIX}
      # Transform configurations
      transforms: "route,unwrap,addOpHeader,addVerHeader,fieldFilter"
      # Extract new record state (flatten envelope)
      transforms.unwrap.type: "io.debezium.transforms.ExtractNewRecordState"
      transforms.unwrap.drop.tombstones: "false"
      # Route partition tables to logical table topic
      transforms.route.type: "io.debezium.transforms.ByLogicalTableRouter"
      transforms.route.topic.regex: "host-inventory\\.hbi\\.hosts.*"
      transforms.route.topic.replacement: "host-inventory.hbi.hosts"
      # Add static headers
      transforms.addOpHeader.type: "org.apache.kafka.connect.transforms.InsertHeader"
      transforms.addOpHeader.header: "operation"
      transforms.addOpHeader.value.literal: "migration"
      transforms.addVerHeader.type: "org.apache.kafka.connect.transforms.InsertHeader"
      transforms.addVerHeader.header: "version"
      transforms.addVerHeader.value.literal: "v1beta2"
      transforms.fieldFilter.type: "org.apache.kafka.connect.transforms.ReplaceField$Value"
      transforms.fieldFilter.include: "id,ansible_host,insights_id,satellite_id,subscription_manager_id,groups"
parameters:
- name: ENV_NAME
  description: ClowdEnvironment name (ephemeral, stage, prod)
  required: true
- name: BOOTSTRAP_SERVERS
  description: Kafka Bootstrap server(s) URL(s)
  required: true
- name: DB_SECRET_NAME
  description: Name of the secret that contains database credentials
  required: true
- name: KAFKA_CONNECT_INSTANCE
  value: kessel-kafka-connect
  description: Name of the target Kafka Connect instance for Connector
- name: CONNECTOR_STATE
  description: Defines the state the connector should be deployed in ('stopped', 'running', 'paused' only)
  value: stopped
- name: MAX_TASKS
  value: "1"
  description: How many tasks the Kafka Connect instance can create to process this Connector's work
- name: TOPIC_HEARTBEAT_PREFIX
  value: debezium-heartbeat
  description: Prefix for the connector heartbeat topic
- name: DEBEZIUM_ACTION_QUERY
  value: "SELECT pg_logical_emit_message(false, 'heartbeat', now()::varchar);"
  description: Query action that runs for each heartbeat event
- name: DEBEZIUM_HEARTBEAT_INTERVAL_MS
  value: "300000"
  description: The interval for the Debezium heartbeat in ms

